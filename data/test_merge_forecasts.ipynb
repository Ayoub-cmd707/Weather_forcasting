{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dba92a3f",
   "metadata": {},
   "source": [
    "# Test Merge Forecasts Notebook\n",
    "\n",
    "Dit Jupyter Notebook laadt en merge forecast-bestanden zonder ze op te slaan. Alle stappen worden gelogd in de console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7291d730-0889-4c3e-a0ad-9edbb30f4081",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import logging\n",
    "import glob\n",
    "import xarray as xr\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# --- Configuratie ---\n",
    "MAX_FILES   = 10\n",
    "PATH1       = \"/home/jupyter-ayoub/data/EUPP\"\n",
    "PATH2       = \"/home/jupyter-aaron/Postprocessing/PP_EUPP/data/EUPP\"\n",
    "OUTPUT_DIR  = \"/home/jupyter-ayoub/data/test\"\n",
    "OUTPUT_STORE= \"combined_forecasts.zarr\"\n",
    "\n",
    "def setup_logging():\n",
    "    \"\"\"Zet logging naar STDOUT op DEBUG-niveau.\"\"\"\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    handler = logging.StreamHandler(sys.stdout)\n",
    "    handler.setFormatter(logging.Formatter(\"%(asctime)s | %(levelname)-8s | %(message)s\"))\n",
    "    logger.handlers.clear()\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "def find_files(path, limit=None):\n",
    "    pattern = os.path.join(path, \"output.sfc.*.nc\")\n",
    "    files = sorted(glob.glob(pattern))\n",
    "    logging.info(f\"Gevonden {len(files)} bestanden in {path}\")\n",
    "    if limit:\n",
    "        files = files[:limit]\n",
    "        logging.info(f\"  → Beperk tot eerste {limit} bestanden\")\n",
    "    for f in files:\n",
    "        logging.debug(f\"    • {f}\")\n",
    "    return files\n",
    "\n",
    "def preprocess(ds):\n",
    "    \"\"\"Drop 'valid_time' om MergeError te voorkomen.\"\"\"\n",
    "    return ds.drop_vars(\"valid_time\", errors=\"ignore\")\n",
    "\n",
    "def open_group(files, name):\n",
    "    \"\"\"Open een set NetCDF-bestanden via nested concatenation over time.\"\"\"\n",
    "    logging.info(f\"Open groep '{name}' met {len(files)} bestanden …\")\n",
    "    ds = xr.open_mfdataset(\n",
    "        files,\n",
    "        combine=\"nested\",\n",
    "        concat_dim=\"time\",\n",
    "        preprocess=preprocess,\n",
    "        parallel=False,\n",
    "        data_vars=\"minimal\",\n",
    "        coords=\"minimal\",\n",
    "        compat=\"override\"\n",
    "    )\n",
    "    logging.info(f\"  → '{name}' dims: {ds.dims}\")\n",
    "    logging.info(f\"  → '{name}' vars: {list(ds.data_vars.keys())}\")\n",
    "    return ds\n",
    "\n",
    "def main():\n",
    "    setup_logging()\n",
    "    logging.info(\"=== Merge & inspect all variables ===\")\n",
    "\n",
    "    # 1) Bestanden vinden\n",
    "    files1 = find_files(PATH1, limit=MAX_FILES)\n",
    "    files2 = find_files(PATH2, limit=MAX_FILES)\n",
    "    if not (files1 or files2):\n",
    "        logging.error(\"Geen bestanden gevonden in beide paden!\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # 2) Groepen inladen\n",
    "    ds1 = open_group(files1, name=\"EUPP-ayoub\")\n",
    "    ds2 = open_group(files2, name=\"EUPP-aaron\")\n",
    "\n",
    "    # 3) Merger\n",
    "    logging.info(\"Start merge van beide groepen…\")\n",
    "    ds_all = xr.merge([files1, files2])\n",
    "    logging.info(\"Merge compleet!\")\n",
    "    logging.info(f\"  dims: {ds_all.dims}\")\n",
    "    logging.info(f\"  vars ({len(ds_all.data_vars)}): {list(ds_all.data_vars.keys())}\")\n",
    "\n",
    "    # 4) Per variabele een apart Dataset printen\n",
    "    for var in ds_all.data_vars:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"Variable: {var}\")\n",
    "        print(\"=\"*80)\n",
    "        # ds_all[[var]] geeft een Dataset met precies die ene variabele\n",
    "        print(ds_all[[var]])\n",
    "\n",
    "    # 5) (Optioneel) schrijven naar Zarr\n",
    "    #os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    #output_path = os.path.join(OUTPUT_DIR, OUTPUT_STORE)\n",
    "    #logging.info(f\"Schrijf merged dataset naar Zarr: {output_path}\")\n",
    "    # ds_all.to_zarr(output_path, mode=\"w\")\n",
    "    #logging.info(\"Klaar – Zarr-store geschreven.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "833d613e-5784-4791-bf2a-b91a0ad4da33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-24 15:27:47,149 | INFO     | === Merge + export met volledige year+time dims ===\n",
      "2025-04-24 15:27:47,164 | INFO     | Gevonden 4180 bestanden in /home/jupyter-ayoub/data/EUPP\n",
      "2025-04-24 15:27:47,164 | INFO     |   → Gebruik eerste 10\n",
      "2025-04-24 15:27:47,165 | INFO     |   → Gemaakt 1 jaar-groepen voor nested combine\n",
      "2025-04-24 15:27:47,165 | INFO     | Nested combine voor groep 'EUPP-ayoub' met dims ['year','time'] …\n",
      "2025-04-24 15:27:47,382 | INFO     |   → 'EUPP-ayoub' dims: FrozenMappingWarningOnValuesAccess({'time': 10, 'year': 1, 'number': 11, 'step': 20, 'latitude': 32, 'longitude': 33})\n",
      "2025-04-24 15:27:47,383 | INFO     |   → 'EUPP-ayoub' vars: ['q', 'tp6', 'ssr6', 'str6', 'ssrd6', 'strd6', 'ssrd6_obs']\n",
      "2025-04-24 15:27:47,397 | INFO     | Gevonden 4180 bestanden in /home/jupyter-aaron/Postprocessing/PP_EUPP/data/EUPP\n",
      "2025-04-24 15:27:47,397 | INFO     |   → Gebruik eerste 10\n",
      "2025-04-24 15:27:47,398 | INFO     |   → Gemaakt 1 jaar-groepen voor nested combine\n",
      "2025-04-24 15:27:47,398 | INFO     | Nested combine voor groep 'EUPP-aaron' met dims ['year','time'] …\n",
      "2025-04-24 15:27:47,783 | INFO     |   → 'EUPP-aaron' dims: FrozenMappingWarningOnValuesAccess({'time': 10, 'year': 1, 'number': 11, 'step': 20, 'latitude': 32, 'longitude': 33})\n",
      "2025-04-24 15:27:47,783 | INFO     |   → 'EUPP-aaron' vars: ['t2m', 'z', 't', 'u10', 'v10', 'tcc', 'sd', 'mx2t6', 'mn2t6', 'w10', 'u100', 'w100', 'u', 'w700', 'p10fg6', 'v100', 'v']\n",
      "2025-04-24 15:27:47,783 | INFO     | Mergen van beide groepen…\n",
      "2025-04-24 15:27:47,785 | INFO     |   → merged dims: FrozenMappingWarningOnValuesAccess({'time': 10, 'number': 11, 'year': 1, 'step': 20, 'latitude': 32, 'longitude': 33})\n",
      "2025-04-24 15:27:47,786 | INFO     |   → merged vars: ['q', 'tp6', 'ssr6', 'str6', 'ssrd6', 'strd6', 'ssrd6_obs', 't2m', 'z', 't', 'u10', 'v10', 'tcc', 'sd', 'mx2t6', 'mn2t6', 'w10', 'u100', 'w100', 'u', 'w700', 'p10fg6', 'v100', 'v']\n",
      "2025-04-24 15:27:47,786 | INFO     | Schrijven per (year,time) naar /home/jupyter-ayoub/data/test/forecasts …\n",
      "2025-04-24 15:27:47,907 | DEBUG    | Saved /home/jupyter-ayoub/data/test/forecasts/output.sfc.0.20170102.nc\n",
      "2025-04-24 15:27:48,067 | DEBUG    | Saved /home/jupyter-ayoub/data/test/forecasts/output.sfc.0.20170105.nc\n",
      "2025-04-24 15:27:48,181 | DEBUG    | Saved /home/jupyter-ayoub/data/test/forecasts/output.sfc.0.20170109.nc\n",
      "2025-04-24 15:27:48,295 | DEBUG    | Saved /home/jupyter-ayoub/data/test/forecasts/output.sfc.0.20170112.nc\n",
      "2025-04-24 15:27:48,409 | DEBUG    | Saved /home/jupyter-ayoub/data/test/forecasts/output.sfc.0.20170116.nc\n",
      "2025-04-24 15:27:48,522 | DEBUG    | Saved /home/jupyter-ayoub/data/test/forecasts/output.sfc.0.20170119.nc\n",
      "2025-04-24 15:27:48,634 | DEBUG    | Saved /home/jupyter-ayoub/data/test/forecasts/output.sfc.0.20170123.nc\n",
      "2025-04-24 15:27:48,743 | DEBUG    | Saved /home/jupyter-ayoub/data/test/forecasts/output.sfc.0.20170126.nc\n",
      "2025-04-24 15:27:48,854 | DEBUG    | Saved /home/jupyter-ayoub/data/test/forecasts/output.sfc.0.20170130.nc\n",
      "2025-04-24 15:27:48,965 | DEBUG    | Saved /home/jupyter-ayoub/data/test/forecasts/output.sfc.0.20170202.nc\n",
      "2025-04-24 15:27:48,965 | INFO     | Klaar – alle bestanden zijn weggeschreven.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import logging\n",
    "import glob\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "# --- Configuratie ---\n",
    "MAX_FILES    = 10\n",
    "PATH1        = \"/home/jupyter-ayoub/data/EUPP\"\n",
    "PATH2        = \"/home/jupyter-aaron/Postprocessing/PP_EUPP/data/EUPP\"\n",
    "OUTPUT_ROOT  = \"/home/jupyter-ayoub/data/test\"\n",
    "FORECAST_DIR = os.path.join(OUTPUT_ROOT, \"forecasts\")\n",
    "\n",
    "def setup_logging():\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    h = logging.StreamHandler(sys.stdout)\n",
    "    h.setFormatter(logging.Formatter(\"%(asctime)s | %(levelname)-8s | %(message)s\"))\n",
    "    logger.handlers.clear()\n",
    "    logger.addHandler(h)\n",
    "\n",
    "def find_files(path, limit=None):\n",
    "    pattern = os.path.join(path, \"output.sfc.*.nc\")\n",
    "    files = sorted(glob.glob(pattern))\n",
    "    logging.info(f\"Gevonden {len(files)} bestanden in {path}\")\n",
    "    if limit:\n",
    "        files = files[:limit]\n",
    "        logging.info(f\"  → Gebruik eerste {limit}\")\n",
    "    return files\n",
    "\n",
    "def build_nested_file_list(files):\n",
    "    \"\"\"\n",
    "    Groepeer op jaar (uit de naam output.sfc.<year>.<date>.nc) en maak\n",
    "    een geneste lijst per jaar:\n",
    "      [[f_yr0_time0, f_yr0_time1, …], [f_yr1_time0, …], …]\n",
    "    \"\"\"\n",
    "    groups = OrderedDict()\n",
    "    for f in files:\n",
    "        year = int(os.path.basename(f).split('.')[2])\n",
    "        groups.setdefault(year, []).append(f)\n",
    "    # zorg dat binnen elk jaar de files gesorteerd staan\n",
    "    nested = [groups[y] for y in sorted(groups)]\n",
    "    logging.info(f\"  → Gemaakt {len(nested)} jaar-groepen voor nested combine\")\n",
    "    return nested\n",
    "\n",
    "def preprocess(ds):\n",
    "    # drop conflicterende coord\n",
    "    return ds.drop_vars(\"valid_time\", errors=\"ignore\")\n",
    "\n",
    "def open_group(path, name):\n",
    "    \"\"\"\n",
    "    Open alle files in `path` als één Dataset met echte year- én time-dimensie.\n",
    "    \"\"\"\n",
    "    files = find_files(path, limit=MAX_FILES)\n",
    "    nested = build_nested_file_list(files)\n",
    "    logging.info(f\"Nested combine voor groep '{name}' met dims ['year','time'] …\")\n",
    "    ds = xr.open_mfdataset(\n",
    "        nested,\n",
    "        combine=\"nested\",\n",
    "        concat_dim=[\"year\", \"time\"],\n",
    "        preprocess=preprocess,\n",
    "        parallel=False,\n",
    "        data_vars=\"minimal\",\n",
    "        coords=\"minimal\",\n",
    "        compat=\"override\"\n",
    "    )\n",
    "    # zet dims in de door jou gewenste volgorde\n",
    "    desired = [\"time\",\"number\",\"year\",\"step\",\"surface\",\"latitude\",\"longitude\"]\n",
    "    ds = ds.transpose(*[d for d in desired if d in ds.dims])\n",
    "    logging.info(f\"  → '{name}' dims: {ds.dims}\")\n",
    "    logging.info(f\"  → '{name}' vars: {list(ds.data_vars)}\")\n",
    "    return ds\n",
    "\n",
    "def merge_groups(ds1, ds2):\n",
    "    logging.info(\"Mergen van beide groepen…\")\n",
    "    ds = xr.merge([ds1, ds2], compat=\"override\")\n",
    "    logging.info(f\"  → merged dims: {ds.dims}\")\n",
    "    logging.info(f\"  → merged vars: {list(ds.data_vars)}\")\n",
    "    return ds\n",
    "\n",
    "def save_per_timestep(ds, out_dir, prefix=\"output.sfc\"):\n",
    "    \"\"\"Schrijf per (year,time) precies één bestand weg.\"\"\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    for y in range(ds.sizes[\"year\"]):\n",
    "        for t in range(ds.sizes[\"time\"]):\n",
    "            date = pd.to_datetime(ds.time.values[t]).strftime(\"%Y%m%d\")\n",
    "            fname = f\"{prefix}.{y}.{date}.nc\"\n",
    "            fpath = os.path.join(out_dir, fname)\n",
    "            ds.isel(year=y, time=t).to_netcdf(fpath)\n",
    "            logging.debug(f\"Saved {fpath}\")\n",
    "\n",
    "def main():\n",
    "    setup_logging()\n",
    "    logging.info(\"=== Merge + export met volledige year+time dims ===\")\n",
    "\n",
    "    ds1 = open_group(PATH1, \"EUPP-ayoub\")\n",
    "    ds2 = open_group(PATH2, \"EUPP-aaron\")\n",
    "\n",
    "    ds_all = merge_groups(ds1, ds2)\n",
    "\n",
    "    logging.info(f\"Schrijven per (year,time) naar {FORECAST_DIR} …\")\n",
    "    save_per_timestep(ds_all, FORECAST_DIR)\n",
    "\n",
    "    logging.info(\"Klaar – alle bestanden zijn weggeschreven.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c34efa-1f64-40ab-a62b-bde2e2c5f46e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
