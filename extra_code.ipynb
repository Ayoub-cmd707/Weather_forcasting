{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4098138a-0e7b-43e3-b2f8-5aad505a6569",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/home/jupyter-ayoub/MEM/batches\"  # Pas dit aan\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "batch_size = 10\n",
    "total_time = rearranged_10.sizes[\"time\"]\n",
    "\n",
    "for i in range(0, total_time, batch_size):\n",
    "    #print(f\"Processing time slice {i}:{i+batch_size}...\")\n",
    "\n",
    "    batch = rearranged_10.isel(time=slice(i, min(i+batch_size, total_time)))\n",
    "    batch_np = batch.values.astype(np.float32)\n",
    "    batch_tensor = torch.from_numpy(batch_np)\n",
    "\n",
    "    # Opslaan naar bestand (bv. batch_000.pt)\n",
    "    torch.save(batch_tensor, os.path.join(save_path, f\"fcs_batch_{i:04d}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcabdb8-803f-42b9-8687-6e977d4b2c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import glob\n",
    "\n",
    "files = sorted(glob.glob(\"/home/jupyter-ayoub/MEM/batches/fcs_batch_*.pt\"))\n",
    "fcs_whole_tensor = None\n",
    "\n",
    "for i in range(0, len(files), 5):  # per 5 bestanden\n",
    "    batch_group = [torch.load(f) for f in files[i:i+5]]\n",
    "    partial = torch.cat(batch_group, dim=0)\n",
    "\n",
    "    if fcs_whole_tensor is None:\n",
    "        fcs_whole_tensor = partial\n",
    "    else:\n",
    "        fcs_whole_tensor = torch.cat([fcs_whole_tensor, partial], dim=0)\n",
    "\n",
    "    # geheugen vrijmaken\n",
    "    del batch_group, partial\n",
    "    torch.cuda.empty_cache()  # indien nodig\n",
    "\n",
    "print(\"Totale shape:\", fcs_whole_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ca0d4c-4b21-487f-a03e-1b3ecf0a9303",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(fcs_whole_tensor, \"/home/jupyter-ayoub/MEM/fcs_whole_tensor.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677201b8-b956-4d80-87ba-b17ca9823a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcs_whole_tensor = torch.load(\"/home/jupyter-ayoub/MEM/fcs_whole_tensor.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368d22f4-a607-400e-aa83-414718ef3b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "total_time = fcs_10.sizes[\"time\"]\n",
    "save_path = \"/home/jupyter-ayoub/MEM/batches_unnorm\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "for i in range(0, total_time, batch_size):\n",
    "    print(f\"Processing time slice {i}:{i+batch_size}\")\n",
    "    \n",
    "    batch = fcs_10.isel(time=slice(i, i+batch_size))  # selecteer klein blok\n",
    "    fcs_array = batch.to_array(dim=\"variable\")\n",
    "    \n",
    "    # Zet om naar float32 en PyTorch tensor\n",
    "    fcs_np = fcs_array.transpose('time', 'number', 'step', 'latitude', 'longitude', 'variable').values.astype(np.float32)\n",
    "    fcs_tensor = torch.from_numpy(fcs_np)\n",
    "    \n",
    "    torch.save(fcs_tensor, f\"{save_path}/fcs_unnorm_batch_{i:04d}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b49fa0-61c7-4ba0-b0b5-3131eb3ac202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Pad naar je ongenormaliseerde batches\n",
    "files = sorted(glob.glob(\"/home/jupyter-ayoub/MEM/batches_unnorm/fcs_unnorm_batch_*.pt\"))\n",
    "\n",
    "# Beginwaarde\n",
    "fcs_whole_notnorm_tensor = None\n",
    "\n",
    "# Voeg samen in stukken van 5 bestanden\n",
    "for i in range(0, len(files), 5):\n",
    "    print(f\"Loading batches {i} to {i+4}\")\n",
    "\n",
    "    batch_group = [torch.load(f) for f in files[i:i+5]]\n",
    "    partial = torch.cat(batch_group, dim=0)\n",
    "\n",
    "    if fcs_whole_notnorm_tensor is None:\n",
    "        fcs_whole_notnorm_tensor = partial\n",
    "    else:\n",
    "        fcs_whole_notnorm_tensor = torch.cat([fcs_whole_notnorm_tensor, partial], dim=0)\n",
    "\n",
    "    # RAM opschonen\n",
    "    del batch_group, partial\n",
    "    torch.cuda.empty_cache()  # als je op GPU zit, anders niet nodig\n",
    "\n",
    "print(\"Totale shape fcs_whole_notnorm_tensor:\", fcs_whole_notnorm_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22aca93-ec46-4747-ab26-487e192f2db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcs_whole_notnorm_tensor = fcs_whole_notnorm_tensor.to(torch.float32)\n",
    "torch.save(fcs_whole_notnorm_tensor, \"/home/jupyter-ayoub/MEM/fcs_whole_notnorm_tensor.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c484623-83f1-4b94-9315-3ca9c104ea00",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcs_whole_notnorm_tensor = torch.load(\"/home/jupyter-ayoub/MEM/fcs_whole_notnorm_tensor.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b154232-36e0-42e4-85cc-51365e3198dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_one = postpro_10_whole[...,0]\n",
    "#print(fcs_whole_notnorm_tensor)\n",
    "values_tar = fcs_whole_notnorm_tensor[:,:,:,:,:,5] #torch.Size([26, 11, 32, 33])\n",
    "#print(values_tar)\n",
    "scale_std, scale_mean= torch.std_mean(values_tar, dim=1, unbiased=True)\n",
    "scaled_ensemble_one=(ensemble_one * scale_std.unsqueeze(1) + scale_mean.unsqueeze(1)).permute(1, 0, 2, 3, 4)\n",
    "#print(scaled_ensemble_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef386103-d655-4dd4-bfc5-d0ee4594b2cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d385e6c2-868c-4d6b-aa08-0eb14e32a1ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_431061/1740415332.py:2: DeprecationWarning: numpy.core is deprecated and has been renamed to numpy._core. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.multiarray.\n",
      "  with torch.serialization.safe_globals([numpy.core.multiarray.scalar]):\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/jupyter-ayoub/results/Transformerweights/ssrd6/Beste_result/epochs50predictors18CRPSKERNELSTEPlambda0.02k3.3.pth\"\n",
    "with torch.serialization.safe_globals([numpy.core.multiarray.scalar]):\n",
    "    data = torch.load(path, map_location=torch.device('cpu'), weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22fed0cd-f062-42bd-9a7e-339cbd732b17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['model', 'crps', 'epoch'])\n"
     ]
    }
   ],
   "source": [
    "print(type(data))        # Is het een dict, een model, of iets anders?\n",
    "if isinstance(data, dict):\n",
    "    print(data.keys())   # Geeft je een overzicht van de onderdelen (bv. model, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2772221-93e6-47dc-bb11-c6cd9718f64a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stel dat het modelparameters zijn opgeslagen onder \"model_state_dict\":\n",
    "model_weights = data.get(\"model_state_dict\", None)\n",
    "if model_weights:\n",
    "    for k, v in model_weights.items():\n",
    "        print(k, v.shape)  # Bekijk layer-namen en tensor shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2a16b3-e9ee-458d-be6c-ba5ad79eb89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_solar_power_from_ssrd6(ssrd6_data, efficiency=0.18, panel_area=1000.0):\n",
    "    \"\"\"\n",
    "    Zet ssrd6 (J/m² over 6 uur) om naar geschat vermogen (W) van een zonne-energiesysteem.\n",
    "    Werkt op een numpy array of xarray DataArray.\n",
    "\n",
    "    Parameters:\n",
    "    - ssrd6_data: ndarray met shape (ensemble, time, lat, lon)\n",
    "    - efficiency: float, systeemefficiëntie (typisch 0.15–0.20)\n",
    "    - panel_area: float, totale paneeloppervlakte in m²\n",
    "\n",
    "    Returns:\n",
    "    - power_output: zelfde shape als input, vermogen in watt\n",
    "    \"\"\"\n",
    "    irradiance_avg = ssrd6_data / (6 * 3600)  # W/m² gemiddeld over 6 uur\n",
    "    power_output = efficiency * irradiance_avg * panel_area  # W\n",
    "\n",
    "    return power_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3141b569-b101-4a62-8a29-d01b3eb1cf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stel: Tformer_one.shape = (11, 8, 32, 33)\n",
    "solar_power_output = compute_solar_power_from_ssrd6(\n",
    "    Tformer_one,\n",
    "    efficiency=0.19,     # bijvoorbeeld voor moderne panelen\n",
    "    panel_area=10000.0   # stel dat je 10.000 m² PV-oppervlak modelleert\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
